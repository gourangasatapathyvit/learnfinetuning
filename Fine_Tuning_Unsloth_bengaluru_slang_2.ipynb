{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gourangasatapathyvit/learnfinetuning/blob/main/Fine_Tuning_Unsloth_bengaluru_slang_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f54e9490",
        "outputId": "0cb599b6-cb13-4a50-8dd1-42d922272a9c"
      },
      "source": [
        "!pip install unsloth[colab-new] --upgrade"
      ],
      "id": "f54e9490",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unsloth[colab-new]\n",
            "  Downloading unsloth-2025.8.10-py3-none-any.whl.metadata (52 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/52.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unsloth_zoo>=2025.8.9 (from unsloth[colab-new])\n",
            "  Downloading unsloth_zoo-2025.8.9-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (2.8.0+cu126)\n",
            "Collecting xformers>=0.0.27.post2 (from unsloth[colab-new])\n",
            "  Downloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting bitsandbytes (from unsloth[colab-new])\n",
            "  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (25.0)\n",
            "Collecting tyro (from unsloth[colab-new])\n",
            "  Downloading tyro-0.9.31-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,>=4.51.3 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (4.55.4)\n",
            "Collecting datasets<4.0.0,>=3.4.1 (from unsloth[colab-new])\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (2.0.2)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (1.10.1)\n",
            "Collecting trl!=0.15.0,!=0.19.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth[colab-new])\n",
            "  Downloading trl-0.22.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.17.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (5.29.5)\n",
            "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.34.4)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.1.9)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.35.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth[colab-new]) (0.23.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth[colab-new]) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth[colab-new]) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (2.32.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth[colab-new]) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth[colab-new]) (1.1.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[colab-new]) (1.11.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,>=4.51.3->unsloth[colab-new]) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,>=4.51.3->unsloth[colab-new]) (0.21.4)\n",
            "Requirement already satisfied: torchao in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.8.9->unsloth[colab-new]) (0.10.0)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo>=2025.8.9->unsloth[colab-new])\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.8.9->unsloth[colab-new]) (11.3.0)\n",
            "Collecting msgspec (from unsloth_zoo>=2025.8.9->unsloth[colab-new])\n",
            "  Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth[colab-new]) (8.7.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth[colab-new]) (0.17.0)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth[colab-new]) (13.9.4)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth[colab-new])\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth[colab-new]) (4.4.4)\n",
            "\u001b[33mWARNING: unsloth 2025.8.10 does not provide the extra 'triton'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (3.12.15)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (2025.8.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth[colab-new]) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth[colab-new]) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->unsloth[colab-new]) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (1.20.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth[colab-new]) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<4.0.0,>=3.4.1->unsloth[colab-new]) (1.17.0)\n",
            "Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.22.1-py3-none-any.whl (544 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m544.8/544.8 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2025.8.9-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.31-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.7/131.7 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth-2025.8.10-py3-none-any.whl (312 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: shtab, msgspec, tyro, xformers, datasets, cut_cross_entropy, bitsandbytes, trl, unsloth_zoo, unsloth\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "Successfully installed bitsandbytes-0.47.0 cut_cross_entropy-25.1.1 datasets-3.6.0 msgspec-0.19.0 shtab-1.7.2 trl-0.22.1 tyro-0.9.31 unsloth-2025.8.10 unsloth_zoo-2025.8.9 xformers-0.0.32.post2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "210a5d12-4f8f-40b2-8b66-37b845d8aa0f",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386,
          "referenced_widgets": [
            "9b72a0f6c0f4497da349ecce6f38b2f8",
            "fd8c487a68df456b89ba2b1c3144db7d",
            "667367c01d5f4c2c9753ae913983e119",
            "9c26fa090a594155a0bfe01229c1d5fd",
            "2d96a633596d4b34b4761a3e623c0316",
            "4d6c4b33a9104f37906f0878e1b26ab7",
            "13e422653b25430b8ce0cb27bb23b365",
            "0c12f031d1f04612b02539aac5a403e1",
            "04499c264630433baa9f86da183433ea",
            "16ba9cd535d4410896dac30b51834f5b",
            "75bbc0db8f2c4e51a9575d7dea2d90b6",
            "a18981d3a00b4be191bbe341ba912c35",
            "20fd252d51d24815b99c10f03118d24f",
            "b6795a7df86a4a76b8e3b8d5ad394c9c",
            "689a5c2a6ea74f97a0e1daeb44cc09c9",
            "3114136116704e299ee1633a5c0a17f6",
            "dd2978f1ccc64ec0ac0d80f4cd34f1da",
            "10de50950e7b49949751077751c9af7c",
            "4440128827c5437ea6d3e15245d07897",
            "5843b164b8314c8e89927d0e3fa48314",
            "bd6c756b62b545f2a4d669d3d20897b9",
            "b34a9905d7654c2c9ebf7f3978af2471",
            "cd6e61bd7eac465ab75b9a3773d277e1",
            "dd8206d943604c2b83e6d88c5e68bf06",
            "d88e9fcb92f3498ca32c31bf63914513",
            "eff954698f854971bde87459bd3683fd",
            "d5301d9c334a42099e797f73f2731370",
            "828359a745aa4a759c7cf8c33f583de8",
            "094ef40f0a4b477aadb1e1e44d7a737d",
            "c7e00b39555e410caa55562c1f8e17eb",
            "3bb2b4ca90db4fd08ca146faec921bf7",
            "92abf0d47bbf40ac9af1a5231313774c",
            "4f53f24fb75f47eaa7bbac7483cfd1f0",
            "019e38df385b4959b0f5f980793fe4ac",
            "401774009faa47fab0ace64b6cc89304",
            "0cb9d3d2da38443c97926135d3e0aa7a",
            "03e98b0375834a539b8dcf36a39f1356",
            "e96b7d3c44aa4055bf22b5c06878adbc",
            "0bdc08ccb64a45fb94041fba3c06ad3e",
            "806b67d71a6746ebaf50eb39d96d3127",
            "8f3816717df3496496cda39a26bdad1e",
            "12bd3f0078714193af933bc57c1c6561",
            "e685780ee9f64543a78cf4c0830738ce",
            "ee5d50db61644839a330653417909b53",
            "8556f5e016a44b5d8a962d89810c20c8",
            "55113d41b3f9438e8677870520eb219f",
            "99f3eb5eaa1f478c984d1ab8d1a46336",
            "08cae4595a0248c38d8112bf10547131",
            "01d36b8549694e02b7e70067a5519f61",
            "d10e35a2ff594297afcb3a1b2f60f241",
            "50d278b85535477189c39c1c7982f9e1",
            "58127cbc4c3a49eb94396d3669197ba4",
            "a5664e2ab7b84a7fb9d9cd8cb68c28e2",
            "e300f8d6e6a74940abdc99551f809dd4",
            "da743f42c9da490eb7c54c91a1074014",
            "6f2fdf337bf341da98f80e8d1fc34e1d",
            "c4a8df337a13491593e723f71dc667d2",
            "b9b97789f993434592ebcda3c18d38e0",
            "754e53a68210409593597768bbac55a7",
            "83507f7fb1ad446ea38eb053d39d2a1f",
            "68a3259574034e38af43cdfff5bd6af5",
            "2fa85f42983e4fa8abe53b5c300e4d25",
            "aea537175b884a6c8061dfedd9d9de5a",
            "dd46cfd6c5294ae69dcf8c68d64e5175",
            "79751f1b6917400e8ee8da67e0147522",
            "c2472e3c55784add99dcce3fc8553e3b",
            "c76212c7a9624699890e0c21542e4fcc",
            "b8f4f8bbdbea425cafd845ba4c2d48b4",
            "ded049550a0e49ae94177580621fec9b",
            "706c09ac924b4ffda2aa8aed6961cd60",
            "30e1f7acde0f4434bed32adc850a14c7",
            "681a2f0f52e54653bc78553760de2f81",
            "520885c09c184e2791cdbd490a7f3ebe",
            "3e44dd314a5f47bdb8e7deae4037fb42",
            "219d468e692b4862b586a178fce1cf5d",
            "6423ea05fc1c49e2b7ff2dbfc24a7fdd",
            "ddd95fdd481048c5af57f296b314a259"
          ]
        },
        "id": "210a5d12-4f8f-40b2-8b66-37b845d8aa0f",
        "outputId": "7a482d78-9820-4d94-df6c-fdbb5d71fe0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.8.10: Fast Mistral patching. Transformers: 4.55.4.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.26G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b72a0f6c0f4497da349ecce6f38b2f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/194 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a18981d3a00b4be191bbe341ba912c35"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd6e61bd7eac465ab75b9a3773d277e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "019e38df385b4959b0f5f980793fe4ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8556f5e016a44b5d8a962d89810c20c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/458 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f2fdf337bf341da98f80e8d1fc34e1d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c76212c7a9624699890e0c21542e4fcc"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = 'unsloth/Phi-3-mini-4k-instruct-bnb-4bit',\n",
        "    max_seq_length = 2048,\n",
        "    dtype = None,\n",
        "    load_in_4bit = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "def create_conversation(sample):\n",
        "\n",
        "  messages = [\n",
        "        {\"role\": \"user\", \"content\": sample[\"question\"]},\n",
        "        {\"role\": \"assistant\", \"content\":sample[\"answer\"]},\n",
        "    ]\n",
        "  return {\n",
        "        \"text\": tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
        "    }\n",
        "\n",
        "\n",
        "dataset = load_dataset(\"samairtimer/bengaluru_slang\", split=\"train\")\n",
        "dataset = dataset.map(create_conversation, remove_columns=dataset.column_names, batched=False)\n",
        "\n",
        "# Split dataset into 80% training samples and 20% test samples\n",
        "# dataset = dataset.train_test_split(test_size=0.2, shuffle=False)\n",
        "\n",
        "# Print formatted user prompt\n",
        "print(dataset[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "3143cf08545449518324abf55accb43e",
            "c48a5e9ef71e4d9b9a8a3d0c5d9b3831",
            "f47fe2a802e548f8a0cbf6b1a91dbb7b",
            "53eb62556a354a91a8c853df5b6acf64",
            "2cbc7eb5c8514ec48d62b34cd527c121",
            "9c86b9bd268843b3a782bd3655f60674",
            "6a94bc4b94ce4f9698a5f286156b7b72",
            "6462989d75354ebc889a868f62b24f7b",
            "716426904c124c1d9415e209fe734014",
            "954afd4b4e68493ba82b815656229ed4",
            "cf5ee6d80bbd47f1a41d4d6f8d044493"
          ]
        },
        "id": "JimWahZ0-dPK",
        "outputId": "b5cef450-b4a6-4f5d-d2bc-55768cf958f8"
      },
      "id": "JimWahZ0-dPK",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3143cf08545449518324abf55accb43e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['<|user|>\\nMacha, where are you? We said 7 PM only no?<|end|>\\n<|assistant|>\\nAiyo, sorry da. Traffic is bejaan today. Swalpa adjust maadi, coming in 10 minutes only.<|end|>\\n<|endoftext|>', '<|user|>\\nHow was the movie yesterday?<|end|>\\n<|assistant|>\\nBombat macha! Action scenes were chindi good. You should have come off, missed a good one only.<|end|>\\n<|endoftext|>']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7d5e3b9-42da-42f0-918e-7f347a4c69f8",
      "metadata": {
        "id": "d7d5e3b9-42da-42f0-918e-7f347a4c69f8",
        "outputId": "7eb827f2-a9b2-4c90-efa0-24ee85662a77"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|████████████████████████████████████████| 300/300 [00:00<00:00, 12113.05 examples/s]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from datasets import Dataset\n",
        "\n",
        "with open(\"people_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "ds = Dataset.from_list(data)\n",
        "\n",
        "def to_text(ex):\n",
        "    resp = ex[\"response\"]\n",
        "    if not isinstance(resp, str):\n",
        "        resp = json.dumps(resp, ensure_ascii=False)\n",
        "    msgs = [\n",
        "        {\"role\": \"user\", \"content\": ex[\"prompt\"]},\n",
        "        {\"role\": \"assistant\", \"content\": resp},\n",
        "    ]\n",
        "    return {\n",
        "        \"text\": tokenizer.apply_chat_template(\n",
        "            msgs, tokenize=False, add_generation_prompt=False\n",
        "        )\n",
        "    }\n",
        "\n",
        "dataset = ds.map(to_text, remove_columns=ds.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "db9044a2-fc17-4b51-abd6-d2bd9e17b1c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db9044a2-fc17-4b51-abd6-d2bd9e17b1c8",
        "outputId": "65cf7899-6873-4dc5-d250-861f36992687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Already have LoRA adapters! We shall skip this step.\n"
          ]
        }
      ],
      "source": [
        "# Config From GitHub (without seed)\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 64,  # rank of matrices (for LoRA)\n",
        "    target_modules=[\n",
        "        'q_proj', 'k_proj', 'v_proj', 'o_proj',\n",
        "        'gate_proj', 'up_proj', 'down_proj',\n",
        "    ],  # which layers to inject LoRA into\n",
        "    lora_alpha = 64 * 2,  # scaling factor, usually 2x rank\n",
        "    lora_dropout = 0,  # no dropout, increase for regularizaiton\n",
        "    bias = 'none',  # bias stays frozen, only learn the low-rank matrices\n",
        "    use_gradient_checkpointing = 'unsloth',  # activate custom checkpointing scheme of Unsloth -> higher compute but less GPU memory when backpropagating\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "84ad258c-4559-4e18-96fe-4e7ce95a80d1",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "84ad258c-4559-4e18-96fe-4e7ce95a80d1",
        "outputId": "ca97fb61-5d73-4f68-893b-c7981d76f340"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 100 | Num Epochs = 5 | Total steps = 65\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 119,537,664 of 3,940,617,216 (3.03% trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [65/65 02:50, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>entropy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.443000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.172200</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.745600</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.477800</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.356200</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.290800</td>\n",
              "      <td>No Log</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=65, training_loss=0.7115202500269964, metrics={'train_runtime': 173.2783, 'train_samples_per_second': 2.886, 'train_steps_per_second': 0.375, 'total_flos': 1475372777472000.0, 'train_loss': 0.7115202500269964, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "from trl import SFTTrainer, SFTConfig\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "trainer = SFTTrainer(  # supervised fine-tuning trainer\n",
        "    model = model,\n",
        "    train_dataset = dataset,\n",
        "    tokenizer = tokenizer,\n",
        "    dataset_text_field = 'text',\n",
        "    max_seq_length = 2048,\n",
        "    args = SFTConfig(\n",
        "        per_device_train_batch_size = 2,        # small batch, fits in GPU\n",
        "        gradient_accumulation_steps = 4,        # effective batch = 8\n",
        "        warmup_steps = 50,                      # smoother warmup\n",
        "        num_train_epochs = 5,                   # train more for style alignment\n",
        "        logging_steps = 10,                     # log less frequently\n",
        "        save_steps = 100,                       # save checkpoints every 100 steps\n",
        "        save_total_limit = 2,                   # keep only last 2 checkpoints\n",
        "        output_dir = \"outputs\",                 # where to store checkpoints/logs\n",
        "        optim = \"adamw_8bit\",                   # 8-bit optimizer for efficiency\n",
        "        learning_rate = 2e-4,                   # slightly higher for LoRA\n",
        "        lr_scheduler_type = \"linear\",           # stable linear decay\n",
        "    ),\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "b2a549af-e86f-4d71-9935-e2e8eaf1df30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2a549af-e86f-4d71-9935-e2e8eaf1df30",
        "outputId": "d9b24fce-49fe-4dc5-fa0c-e1378bc504e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|user|> Chill maadi..dont fall in trap<|end|><|assistant|> Aiyo sisya! That party was bombat. But hey, didn't drink bejaan. Next time I'll come fully prepared only.<|end|>\n"
          ]
        }
      ],
      "source": [
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Chill maadi..dont fall in trap\"\n",
        "    },\n",
        "]\n",
        "\n",
        "# Turn messages to tensor and send to GPU\n",
        "inputs = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generate model response with max 512 tokens and 0.7 temperature, smallest set of tokens with cumulative probability of >= 0.9 are kept for random sampling\n",
        "outputs = model.generate(input_ids=inputs, max_new_tokens=512, use_cache=True, temperature=0.7, do_sample=True, top_p=0.9)\n",
        "\n",
        "response = tokenizer.batch_decode(outputs)[0]\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43afe88f-b781-4d48-bc59-d3e116b69bb5",
      "metadata": {
        "scrolled": true,
        "id": "43afe88f-b781-4d48-bc59-d3e116b69bb5",
        "outputId": "8bcbfc68-afb5-4506-8960-02e2ab0415a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 6.14 out of 31.2 RAM for saving.\n",
            "Unsloth: Saving model... This might take 5 minutes ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|                                                                  | 0/32 [00:00<?, ?it/s]\n",
            "We will save to Disk and not RAM now.\n",
            "100%|█████████████████████████████████████████████████████████| 32/32 [00:07<00:00,  4.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: Converting mistral model. Can use fast conversion = True.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['q4_k_m'] might take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
            "Unsloth: [1] Converting model at gguf_model_scratch_fixed into bf16 GGUF format.\n",
            "The output location will be /home/neuralnine/Documents/Programming/NeuralNine/Recorded/Unsloth_Fine-Tuning/gguf_model_scratch_fixed/unsloth.BF16.gguf\n",
            "This might take 3 minutes...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: Extending gguf_model_scratch_fixed/tokenizer.model with added_tokens.json.\n",
            "Originally tokenizer.model is of size (32000).\n",
            "But we need to extend to sentencepiece vocab size (32011).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:hf-to-gguf:Loading model: gguf_model_scratch_fixed\n",
            "INFO:hf-to-gguf:Model architecture: MistralForCausalLM\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00002.safetensors'\n",
            "INFO:hf-to-gguf:token_embd.weight,           torch.bfloat16 --> BF16, shape = {3072, 32064}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00002.safetensors'\n",
            "INFO:hf-to-gguf:output.weight,               torch.bfloat16 --> BF16, shape = {3072, 32064}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.bfloat16 --> BF16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:output_norm.weight,          torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 4096\n",
            "INFO:hf-to-gguf:gguf: embedding length = 3072\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 8192\n",
            "INFO:hf-to-gguf:gguf: head count = 32\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 32\n",
            "INFO:hf-to-gguf:gguf: rope theta = 10000.0\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
            "INFO:hf-to-gguf:gguf: file type = 32\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:gguf.vocab:Setting special token type bos to 1\n",
            "INFO:gguf.vocab:Setting special token type eos to 32000\n",
            "INFO:gguf.vocab:Setting special token type unk to 0\n",
            "INFO:gguf.vocab:Setting special token type pad to 32009\n",
            "INFO:gguf.vocab:Setting add_bos_token to False\n",
            "INFO:gguf.vocab:Setting add_eos_token to False\n",
            "INFO:gguf.vocab:Setting chat_template to {% for message in messages %}{% if message['role'] == 'system' %}{{'<|system|>\n",
            "' + message['content'] + '<|end|>\n",
            "'}}{% elif message['role'] == 'user' %}{{'<|user|>\n",
            "' + message['content'] + '<|end|>\n",
            "'}}{% elif message['role'] == 'assistant' %}{{'<|assistant|>\n",
            "' + message['content'] + '<|end|>\n",
            "'}}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|assistant|>\n",
            "' }}{% else %}{{ eos_token }}{% endif %}\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:/home/neuralnine/Documents/Programming/NeuralNine/Recorded/Unsloth_Fine-Tuning/gguf_model_scratch_fixed/unsloth.BF16.gguf: n_tensors = 291, total_size = 7.6G\n",
            "Writing: 100%|██████████| 7.64G/7.64G [00:18<00:00, 422Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to /home/neuralnine/Documents/Programming/NeuralNine/Recorded/Unsloth_Fine-Tuning/gguf_model_scratch_fixed/unsloth.BF16.gguf\n",
            "Unsloth: Conversion completed! Output location: /home/neuralnine/Documents/Programming/NeuralNine/Recorded/Unsloth_Fine-Tuning/gguf_model_scratch_fixed/unsloth.BF16.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This might take 20 minutes...\n",
            "main: build = 6082 (5aa1105d)\n",
            "main: built with cc (GCC) 15.1.1 20250729 for x86_64-pc-linux-gnu\n",
            "main: quantizing '/home/neuralnine/Documents/Programming/NeuralNine/Recorded/Unsloth_Fine-Tuning/gguf_model_scratch_fixed/unsloth.BF16.gguf' to '/home/neuralnine/Documents/Programming/NeuralNine/Recorded/Unsloth_Fine-Tuning/gguf_model_scratch_fixed/unsloth.Q4_K_M.gguf' as Q4_K_M using 32 threads\n",
            "llama_model_loader: loaded meta data with 31 key-value pairs and 291 tensors from /home/neuralnine/Documents/Programming/NeuralNine/Recorded/Unsloth_Fine-Tuning/gguf_model_scratch_fixed/unsloth.BF16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Gguf_Model_Scratch_Fixed\n",
            "llama_model_loader: - kv   3:                         general.size_label str              = 3.8B\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072\n",
            "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192\n",
            "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 96\n",
            "llama_model_loader: - kv  13:               llama.attention.value_length u32              = 96\n",
            "llama_model_loader: - kv  14:                          general.file_type u32              = 32\n",
            "llama_model_loader: - kv  15:                           llama.vocab_size u32              = 32064\n",
            "llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 96\n",
            "llama_model_loader: - kv  17:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = default\n",
            "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,32064]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  21:                      tokenizer.ggml.scores arr[f32,32064]   = [-1000.000000, -1000.000000, -1000.00...\n",
            "llama_model_loader: - kv  22:                  tokenizer.ggml.token_type arr[i32,32064]   = [3, 3, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 32000\n",
            "llama_model_loader: - kv  25:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  26:            tokenizer.ggml.padding_token_id u32              = 32009\n",
            "llama_model_loader: - kv  27:               tokenizer.ggml.add_bos_token bool             = false\n",
            "llama_model_loader: - kv  28:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  29:                    tokenizer.chat_template str              = {% for message in messages %}{% if me...\n",
            "llama_model_loader: - kv  30:            tokenizer.ggml.add_space_prefix bool             = false\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type bf16:  226 tensors\n",
            "[   1/ 291]                        output.weight - [ 3072, 32064,     1,     1], type =   bf16, converting to q6_K .. size =   187.88 MiB ->    77.06 MiB\n",
            "[   2/ 291]                   output_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[   3/ 291]                    token_embd.weight - [ 3072, 32064,     1,     1], type =   bf16, converting to q4_K .. size =   187.88 MiB ->    52.84 MiB\n",
            "[   4/ 291]                  blk.0.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[   5/ 291]               blk.0.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[   6/ 291]             blk.0.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[   7/ 291]                  blk.0.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[   8/ 291]                  blk.0.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n",
            "[   9/ 291]                blk.0.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[  10/ 291]                blk.0.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  11/ 291]                blk.0.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  12/ 291]                  blk.0.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  13/ 291]                  blk.1.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  14/ 291]               blk.1.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  15/ 291]             blk.1.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  16/ 291]                  blk.1.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  17/ 291]                  blk.1.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n",
            "[  18/ 291]                blk.1.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[  19/ 291]                blk.1.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  20/ 291]                blk.1.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  21/ 291]                  blk.1.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  22/ 291]                  blk.2.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  23/ 291]               blk.2.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  24/ 291]             blk.2.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  25/ 291]                  blk.2.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  26/ 291]                  blk.2.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n",
            "[  27/ 291]                blk.2.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[  28/ 291]                blk.2.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  29/ 291]                blk.2.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  30/ 291]                  blk.2.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  31/ 291]                  blk.3.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  32/ 291]               blk.3.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  33/ 291]             blk.3.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  34/ 291]                  blk.3.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  35/ 291]                  blk.3.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n",
            "[  36/ 291]                blk.3.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[  37/ 291]                blk.3.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  38/ 291]                blk.3.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  39/ 291]                  blk.3.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  40/ 291]                  blk.4.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  41/ 291]               blk.4.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  42/ 291]             blk.4.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  43/ 291]                  blk.4.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  44/ 291]                  blk.4.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  45/ 291]                blk.4.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  46/ 291]                blk.4.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  47/ 291]                blk.4.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  48/ 291]                  blk.4.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  49/ 291]                  blk.5.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  50/ 291]               blk.5.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  51/ 291]             blk.5.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  52/ 291]                  blk.5.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  53/ 291]                  blk.5.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  54/ 291]                blk.5.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  55/ 291]                blk.5.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  56/ 291]                blk.5.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  57/ 291]                  blk.5.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  58/ 291]                  blk.6.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  59/ 291]               blk.6.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  60/ 291]             blk.6.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  61/ 291]                  blk.6.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  62/ 291]                  blk.6.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n",
            "[  63/ 291]                blk.6.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[  64/ 291]                blk.6.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  65/ 291]                blk.6.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  66/ 291]                  blk.6.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  67/ 291]                  blk.7.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  68/ 291]               blk.7.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  69/ 291]             blk.7.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  70/ 291]                  blk.7.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  71/ 291]                  blk.7.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  72/ 291]                blk.7.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  73/ 291]                blk.7.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  74/ 291]                blk.7.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  75/ 291]                  blk.7.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  76/ 291]                  blk.8.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  77/ 291]               blk.8.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  78/ 291]             blk.8.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  79/ 291]                  blk.8.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  80/ 291]                  blk.8.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  81/ 291]                blk.8.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  82/ 291]                blk.8.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  83/ 291]                blk.8.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  84/ 291]                  blk.8.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  85/ 291]                  blk.9.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  86/ 291]               blk.9.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  87/ 291]             blk.9.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  88/ 291]                  blk.9.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  89/ 291]                  blk.9.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n",
            "[  90/ 291]                blk.9.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[  91/ 291]                blk.9.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  92/ 291]                blk.9.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  93/ 291]                  blk.9.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  94/ 291]                 blk.10.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  95/ 291]              blk.10.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  96/ 291]            blk.10.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  97/ 291]                 blk.10.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  98/ 291]                 blk.10.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  99/ 291]               blk.10.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 100/ 291]               blk.10.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 101/ 291]               blk.10.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 102/ 291]                 blk.10.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 103/ 291]                 blk.11.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 104/ 291]              blk.11.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 105/ 291]            blk.11.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 106/ 291]                 blk.11.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 107/ 291]                 blk.11.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 108/ 291]               blk.11.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 109/ 291]               blk.11.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 110/ 291]               blk.11.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 111/ 291]                 blk.11.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 112/ 291]                 blk.12.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 113/ 291]              blk.12.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 114/ 291]            blk.12.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 115/ 291]                 blk.12.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 116/ 291]                 blk.12.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n",
            "[ 117/ 291]               blk.12.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 118/ 291]               blk.12.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 119/ 291]               blk.12.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 120/ 291]                 blk.12.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 121/ 291]                 blk.13.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 122/ 291]              blk.13.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 123/ 291]            blk.13.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 124/ 291]                 blk.13.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 125/ 291]                 blk.13.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 126/ 291]               blk.13.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 127/ 291]               blk.13.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 128/ 291]               blk.13.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 129/ 291]                 blk.13.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 130/ 291]                 blk.14.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 131/ 291]              blk.14.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 132/ 291]            blk.14.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 133/ 291]                 blk.14.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 134/ 291]                 blk.14.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 135/ 291]               blk.14.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 136/ 291]               blk.14.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 137/ 291]               blk.14.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 138/ 291]                 blk.14.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 139/ 291]                 blk.15.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 140/ 291]              blk.15.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 141/ 291]            blk.15.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 142/ 291]                 blk.15.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 143/ 291]                 blk.15.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n",
            "[ 144/ 291]               blk.15.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 145/ 291]               blk.15.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 146/ 291]               blk.15.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 147/ 291]                 blk.15.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 148/ 291]                 blk.16.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 149/ 291]              blk.16.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 150/ 291]            blk.16.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 151/ 291]                 blk.16.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 152/ 291]                 blk.16.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 153/ 291]               blk.16.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 154/ 291]               blk.16.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 155/ 291]               blk.16.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 156/ 291]                 blk.16.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 157/ 291]                 blk.17.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 158/ 291]              blk.17.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 159/ 291]            blk.17.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 160/ 291]                 blk.17.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 161/ 291]                 blk.17.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 162/ 291]               blk.17.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 163/ 291]               blk.17.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 164/ 291]               blk.17.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 165/ 291]                 blk.17.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 166/ 291]                 blk.18.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 167/ 291]              blk.18.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 168/ 291]            blk.18.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 169/ 291]                 blk.18.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 170/ 291]                 blk.18.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n",
            "[ 171/ 291]               blk.18.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 172/ 291]               blk.18.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 173/ 291]               blk.18.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 174/ 291]                 blk.18.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 175/ 291]                 blk.19.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 176/ 291]              blk.19.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 177/ 291]            blk.19.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 178/ 291]                 blk.19.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 179/ 291]                 blk.19.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 180/ 291]               blk.19.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 181/ 291]               blk.19.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 182/ 291]               blk.19.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 183/ 291]                 blk.19.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 184/ 291]                 blk.20.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 185/ 291]              blk.20.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 186/ 291]            blk.20.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 187/ 291]                 blk.20.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 188/ 291]                 blk.20.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 189/ 291]               blk.20.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 190/ 291]               blk.20.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 191/ 291]               blk.20.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 192/ 291]                 blk.20.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 193/ 291]                 blk.21.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 194/ 291]              blk.21.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 195/ 291]            blk.21.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 196/ 291]                 blk.21.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 197/ 291]                 blk.21.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n",
            "[ 198/ 291]               blk.21.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 199/ 291]               blk.21.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 200/ 291]               blk.21.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 201/ 291]                 blk.21.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 202/ 291]                 blk.22.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 203/ 291]              blk.22.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 204/ 291]            blk.22.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 205/ 291]                 blk.22.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 206/ 291]                 blk.22.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 207/ 291]               blk.22.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 208/ 291]               blk.22.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 209/ 291]               blk.22.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 210/ 291]                 blk.22.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 211/ 291]                 blk.23.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 212/ 291]              blk.23.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 213/ 291]            blk.23.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 214/ 291]                 blk.23.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 215/ 291]                 blk.23.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 216/ 291]               blk.23.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 217/ 291]               blk.23.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 218/ 291]               blk.23.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 219/ 291]                 blk.23.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 220/ 291]                 blk.24.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 221/ 291]              blk.24.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 222/ 291]            blk.24.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 223/ 291]                 blk.24.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 224/ 291]                 blk.24.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n",
            "[ 225/ 291]               blk.24.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 226/ 291]               blk.24.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 227/ 291]               blk.24.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 228/ 291]                 blk.24.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 229/ 291]                 blk.25.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 230/ 291]              blk.25.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 231/ 291]            blk.25.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 232/ 291]                 blk.25.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 233/ 291]                 blk.25.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 234/ 291]               blk.25.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 235/ 291]               blk.25.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 236/ 291]               blk.25.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 237/ 291]                 blk.25.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 238/ 291]                 blk.26.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 239/ 291]              blk.26.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 240/ 291]            blk.26.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 241/ 291]                 blk.26.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 242/ 291]                 blk.26.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 243/ 291]               blk.26.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 244/ 291]               blk.26.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 245/ 291]               blk.26.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 246/ 291]                 blk.26.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 247/ 291]                 blk.27.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 248/ 291]              blk.27.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 249/ 291]            blk.27.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 250/ 291]                 blk.27.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 251/ 291]                 blk.27.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n",
            "[ 252/ 291]               blk.27.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 253/ 291]               blk.27.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 254/ 291]               blk.27.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 255/ 291]                 blk.27.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 256/ 291]                 blk.28.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 257/ 291]              blk.28.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 258/ 291]            blk.28.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 259/ 291]                 blk.28.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 260/ 291]                 blk.28.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n",
            "[ 261/ 291]               blk.28.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 262/ 291]               blk.28.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 263/ 291]               blk.28.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 264/ 291]                 blk.28.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 265/ 291]                 blk.29.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 266/ 291]              blk.29.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 267/ 291]            blk.29.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 268/ 291]                 blk.29.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 269/ 291]                 blk.29.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n",
            "[ 270/ 291]               blk.29.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 271/ 291]               blk.29.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 272/ 291]               blk.29.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 273/ 291]                 blk.29.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 274/ 291]                 blk.30.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 275/ 291]              blk.30.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 276/ 291]            blk.30.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 277/ 291]                 blk.30.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 278/ 291]                 blk.30.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n",
            "[ 279/ 291]               blk.30.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 280/ 291]               blk.30.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 281/ 291]               blk.30.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 282/ 291]                 blk.30.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 283/ 291]                 blk.31.attn_k.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 284/ 291]              blk.31.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 285/ 291]            blk.31.attn_output.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 286/ 291]                 blk.31.attn_q.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[ 287/ 291]                 blk.31.attn_v.weight - [ 3072,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n",
            "[ 288/ 291]               blk.31.ffn_down.weight - [ 8192,  3072,     1,     1], type =   bf16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[ 289/ 291]               blk.31.ffn_gate.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[ 290/ 291]               blk.31.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[ 291/ 291]                 blk.31.ffn_up.weight - [ 3072,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "llama_model_quantize_impl: model size  =  7288.51 MB\n",
            "llama_model_quantize_impl: quant size  =  2210.78 MB\n",
            "\n",
            "main: quantize time = 22085.72 ms\n",
            "main:    total time = 22085.72 ms\n",
            "Unsloth: Conversion completed! Output location: /home/neuralnine/Documents/Programming/NeuralNine/Recorded/Unsloth_Fine-Tuning/gguf_model_scratch_fixed/unsloth.Q4_K_M.gguf\n"
          ]
        }
      ],
      "source": [
        "model.save_pretrained_gguf(\"gguf_model_scratch_fixed\", tokenizer, quantization_method=\"q4_k_m\", maximum_memory_usage = 0.3)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9b72a0f6c0f4497da349ecce6f38b2f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd8c487a68df456b89ba2b1c3144db7d",
              "IPY_MODEL_667367c01d5f4c2c9753ae913983e119",
              "IPY_MODEL_9c26fa090a594155a0bfe01229c1d5fd"
            ],
            "layout": "IPY_MODEL_2d96a633596d4b34b4761a3e623c0316"
          }
        },
        "fd8c487a68df456b89ba2b1c3144db7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d6c4b33a9104f37906f0878e1b26ab7",
            "placeholder": "​",
            "style": "IPY_MODEL_13e422653b25430b8ce0cb27bb23b365",
            "value": "model.safetensors: 100%"
          }
        },
        "667367c01d5f4c2c9753ae913983e119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c12f031d1f04612b02539aac5a403e1",
            "max": 2264298471,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04499c264630433baa9f86da183433ea",
            "value": 2264298471
          }
        },
        "9c26fa090a594155a0bfe01229c1d5fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16ba9cd535d4410896dac30b51834f5b",
            "placeholder": "​",
            "style": "IPY_MODEL_75bbc0db8f2c4e51a9575d7dea2d90b6",
            "value": " 2.26G/2.26G [00:19&lt;00:00, 123MB/s]"
          }
        },
        "2d96a633596d4b34b4761a3e623c0316": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d6c4b33a9104f37906f0878e1b26ab7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13e422653b25430b8ce0cb27bb23b365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c12f031d1f04612b02539aac5a403e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04499c264630433baa9f86da183433ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "16ba9cd535d4410896dac30b51834f5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75bbc0db8f2c4e51a9575d7dea2d90b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a18981d3a00b4be191bbe341ba912c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20fd252d51d24815b99c10f03118d24f",
              "IPY_MODEL_b6795a7df86a4a76b8e3b8d5ad394c9c",
              "IPY_MODEL_689a5c2a6ea74f97a0e1daeb44cc09c9"
            ],
            "layout": "IPY_MODEL_3114136116704e299ee1633a5c0a17f6"
          }
        },
        "20fd252d51d24815b99c10f03118d24f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd2978f1ccc64ec0ac0d80f4cd34f1da",
            "placeholder": "​",
            "style": "IPY_MODEL_10de50950e7b49949751077751c9af7c",
            "value": "generation_config.json: 100%"
          }
        },
        "b6795a7df86a4a76b8e3b8d5ad394c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4440128827c5437ea6d3e15245d07897",
            "max": 194,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5843b164b8314c8e89927d0e3fa48314",
            "value": 194
          }
        },
        "689a5c2a6ea74f97a0e1daeb44cc09c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd6c756b62b545f2a4d669d3d20897b9",
            "placeholder": "​",
            "style": "IPY_MODEL_b34a9905d7654c2c9ebf7f3978af2471",
            "value": " 194/194 [00:00&lt;00:00, 19.3kB/s]"
          }
        },
        "3114136116704e299ee1633a5c0a17f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd2978f1ccc64ec0ac0d80f4cd34f1da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10de50950e7b49949751077751c9af7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4440128827c5437ea6d3e15245d07897": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5843b164b8314c8e89927d0e3fa48314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd6c756b62b545f2a4d669d3d20897b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b34a9905d7654c2c9ebf7f3978af2471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd6e61bd7eac465ab75b9a3773d277e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd8206d943604c2b83e6d88c5e68bf06",
              "IPY_MODEL_d88e9fcb92f3498ca32c31bf63914513",
              "IPY_MODEL_eff954698f854971bde87459bd3683fd"
            ],
            "layout": "IPY_MODEL_d5301d9c334a42099e797f73f2731370"
          }
        },
        "dd8206d943604c2b83e6d88c5e68bf06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_828359a745aa4a759c7cf8c33f583de8",
            "placeholder": "​",
            "style": "IPY_MODEL_094ef40f0a4b477aadb1e1e44d7a737d",
            "value": "tokenizer_config.json: "
          }
        },
        "d88e9fcb92f3498ca32c31bf63914513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7e00b39555e410caa55562c1f8e17eb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bb2b4ca90db4fd08ca146faec921bf7",
            "value": 1
          }
        },
        "eff954698f854971bde87459bd3683fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92abf0d47bbf40ac9af1a5231313774c",
            "placeholder": "​",
            "style": "IPY_MODEL_4f53f24fb75f47eaa7bbac7483cfd1f0",
            "value": " 3.34k/? [00:00&lt;00:00, 307kB/s]"
          }
        },
        "d5301d9c334a42099e797f73f2731370": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "828359a745aa4a759c7cf8c33f583de8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "094ef40f0a4b477aadb1e1e44d7a737d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7e00b39555e410caa55562c1f8e17eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3bb2b4ca90db4fd08ca146faec921bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92abf0d47bbf40ac9af1a5231313774c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f53f24fb75f47eaa7bbac7483cfd1f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "019e38df385b4959b0f5f980793fe4ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_401774009faa47fab0ace64b6cc89304",
              "IPY_MODEL_0cb9d3d2da38443c97926135d3e0aa7a",
              "IPY_MODEL_03e98b0375834a539b8dcf36a39f1356"
            ],
            "layout": "IPY_MODEL_e96b7d3c44aa4055bf22b5c06878adbc"
          }
        },
        "401774009faa47fab0ace64b6cc89304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bdc08ccb64a45fb94041fba3c06ad3e",
            "placeholder": "​",
            "style": "IPY_MODEL_806b67d71a6746ebaf50eb39d96d3127",
            "value": "tokenizer.model: 100%"
          }
        },
        "0cb9d3d2da38443c97926135d3e0aa7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f3816717df3496496cda39a26bdad1e",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12bd3f0078714193af933bc57c1c6561",
            "value": 499723
          }
        },
        "03e98b0375834a539b8dcf36a39f1356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e685780ee9f64543a78cf4c0830738ce",
            "placeholder": "​",
            "style": "IPY_MODEL_ee5d50db61644839a330653417909b53",
            "value": " 500k/500k [00:00&lt;00:00, 991kB/s]"
          }
        },
        "e96b7d3c44aa4055bf22b5c06878adbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bdc08ccb64a45fb94041fba3c06ad3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "806b67d71a6746ebaf50eb39d96d3127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f3816717df3496496cda39a26bdad1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12bd3f0078714193af933bc57c1c6561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e685780ee9f64543a78cf4c0830738ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee5d50db61644839a330653417909b53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8556f5e016a44b5d8a962d89810c20c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55113d41b3f9438e8677870520eb219f",
              "IPY_MODEL_99f3eb5eaa1f478c984d1ab8d1a46336",
              "IPY_MODEL_08cae4595a0248c38d8112bf10547131"
            ],
            "layout": "IPY_MODEL_01d36b8549694e02b7e70067a5519f61"
          }
        },
        "55113d41b3f9438e8677870520eb219f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d10e35a2ff594297afcb3a1b2f60f241",
            "placeholder": "​",
            "style": "IPY_MODEL_50d278b85535477189c39c1c7982f9e1",
            "value": "added_tokens.json: 100%"
          }
        },
        "99f3eb5eaa1f478c984d1ab8d1a46336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58127cbc4c3a49eb94396d3669197ba4",
            "max": 293,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5664e2ab7b84a7fb9d9cd8cb68c28e2",
            "value": 293
          }
        },
        "08cae4595a0248c38d8112bf10547131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e300f8d6e6a74940abdc99551f809dd4",
            "placeholder": "​",
            "style": "IPY_MODEL_da743f42c9da490eb7c54c91a1074014",
            "value": " 293/293 [00:00&lt;00:00, 15.2kB/s]"
          }
        },
        "01d36b8549694e02b7e70067a5519f61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d10e35a2ff594297afcb3a1b2f60f241": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50d278b85535477189c39c1c7982f9e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58127cbc4c3a49eb94396d3669197ba4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5664e2ab7b84a7fb9d9cd8cb68c28e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e300f8d6e6a74940abdc99551f809dd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da743f42c9da490eb7c54c91a1074014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f2fdf337bf341da98f80e8d1fc34e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4a8df337a13491593e723f71dc667d2",
              "IPY_MODEL_b9b97789f993434592ebcda3c18d38e0",
              "IPY_MODEL_754e53a68210409593597768bbac55a7"
            ],
            "layout": "IPY_MODEL_83507f7fb1ad446ea38eb053d39d2a1f"
          }
        },
        "c4a8df337a13491593e723f71dc667d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68a3259574034e38af43cdfff5bd6af5",
            "placeholder": "​",
            "style": "IPY_MODEL_2fa85f42983e4fa8abe53b5c300e4d25",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "b9b97789f993434592ebcda3c18d38e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aea537175b884a6c8061dfedd9d9de5a",
            "max": 458,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd46cfd6c5294ae69dcf8c68d64e5175",
            "value": 458
          }
        },
        "754e53a68210409593597768bbac55a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79751f1b6917400e8ee8da67e0147522",
            "placeholder": "​",
            "style": "IPY_MODEL_c2472e3c55784add99dcce3fc8553e3b",
            "value": " 458/458 [00:00&lt;00:00, 27.7kB/s]"
          }
        },
        "83507f7fb1ad446ea38eb053d39d2a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68a3259574034e38af43cdfff5bd6af5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fa85f42983e4fa8abe53b5c300e4d25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aea537175b884a6c8061dfedd9d9de5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd46cfd6c5294ae69dcf8c68d64e5175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79751f1b6917400e8ee8da67e0147522": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2472e3c55784add99dcce3fc8553e3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c76212c7a9624699890e0c21542e4fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8f4f8bbdbea425cafd845ba4c2d48b4",
              "IPY_MODEL_ded049550a0e49ae94177580621fec9b",
              "IPY_MODEL_706c09ac924b4ffda2aa8aed6961cd60"
            ],
            "layout": "IPY_MODEL_30e1f7acde0f4434bed32adc850a14c7"
          }
        },
        "b8f4f8bbdbea425cafd845ba4c2d48b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_681a2f0f52e54653bc78553760de2f81",
            "placeholder": "​",
            "style": "IPY_MODEL_520885c09c184e2791cdbd490a7f3ebe",
            "value": "tokenizer.json: "
          }
        },
        "ded049550a0e49ae94177580621fec9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e44dd314a5f47bdb8e7deae4037fb42",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_219d468e692b4862b586a178fce1cf5d",
            "value": 1
          }
        },
        "706c09ac924b4ffda2aa8aed6961cd60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6423ea05fc1c49e2b7ff2dbfc24a7fdd",
            "placeholder": "​",
            "style": "IPY_MODEL_ddd95fdd481048c5af57f296b314a259",
            "value": " 1.84M/? [00:00&lt;00:00, 54.4MB/s]"
          }
        },
        "30e1f7acde0f4434bed32adc850a14c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "681a2f0f52e54653bc78553760de2f81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "520885c09c184e2791cdbd490a7f3ebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e44dd314a5f47bdb8e7deae4037fb42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "219d468e692b4862b586a178fce1cf5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6423ea05fc1c49e2b7ff2dbfc24a7fdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddd95fdd481048c5af57f296b314a259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3143cf08545449518324abf55accb43e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c48a5e9ef71e4d9b9a8a3d0c5d9b3831",
              "IPY_MODEL_f47fe2a802e548f8a0cbf6b1a91dbb7b",
              "IPY_MODEL_53eb62556a354a91a8c853df5b6acf64"
            ],
            "layout": "IPY_MODEL_2cbc7eb5c8514ec48d62b34cd527c121"
          }
        },
        "c48a5e9ef71e4d9b9a8a3d0c5d9b3831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c86b9bd268843b3a782bd3655f60674",
            "placeholder": "​",
            "style": "IPY_MODEL_6a94bc4b94ce4f9698a5f286156b7b72",
            "value": "Map: 100%"
          }
        },
        "f47fe2a802e548f8a0cbf6b1a91dbb7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6462989d75354ebc889a868f62b24f7b",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_716426904c124c1d9415e209fe734014",
            "value": 100
          }
        },
        "53eb62556a354a91a8c853df5b6acf64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_954afd4b4e68493ba82b815656229ed4",
            "placeholder": "​",
            "style": "IPY_MODEL_cf5ee6d80bbd47f1a41d4d6f8d044493",
            "value": " 100/100 [00:00&lt;00:00, 1325.59 examples/s]"
          }
        },
        "2cbc7eb5c8514ec48d62b34cd527c121": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c86b9bd268843b3a782bd3655f60674": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a94bc4b94ce4f9698a5f286156b7b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6462989d75354ebc889a868f62b24f7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "716426904c124c1d9415e209fe734014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "954afd4b4e68493ba82b815656229ed4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf5ee6d80bbd47f1a41d4d6f8d044493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}